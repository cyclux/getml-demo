{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORA - Categorizing academic publications using getML\n",
    "\n",
    "In this notebook, we compare getML against extant approaches in the relational learning literature on the CORA data set, which is often used for benchmarking. We demonstrate that getML outperforms the state of the art in the relational learning literature on this data set. Beyond the benchmarking aspects, this notebooks showcases getML's excellent capabilities in dealing with categorical data.\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Prediction type: __Classification model__\n",
    "- Domain: __Academia__\n",
    "- Prediction target: __The category of a paper__ \n",
    "- Population size: __2708__\n",
    "\n",
    "_Author: Dr. Patrick Urbanke_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "CORA is a well-known benchmarking dataset in the academic literature on relational learning. The dataset contains 2708 scientific publications on machine learning. The papers are divided into 7 categories. The challenge is to predict the category of a paper based on the papers it cites, the papers it is cited by and keywords contained in the paper.\n",
    "\n",
    "It has been downloaded from the [CTU Prague relational learning repository](https://relational.fit.cvut.cz/dataset/CORA) (Motl and Schulte, 2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A web frontend for getML\n",
    "\n",
    "The getML monitor is a frontend built to support your work with getML. The getML monitor displays information such as the imported data frames, trained pipelines and allows easy data and feature exploration. You can launch the getML monitor [here](http://localhost:1709)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is this running?\n",
    "\n",
    "Your getML live session is running inside a docker container on [mybinder.org](https://mybinder.org/), a service built by the Jupyter community and funded by Google Cloud, OVH, GESIS Notebooks and the Turing Institute. As it is a free service, this session will shut down after 10 minutes of inactivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started with the analysis and set up your session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Connected to project 'cora'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "from urllib import request\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline  \n",
    "\n",
    "#import pyspark\n",
    "import getml\n",
    "\n",
    "getml.engine.set_project('cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = getml.database.connect_hana(\n",
    "    host=\"localhost\",\n",
    "    default_schema=\"HOTEL\",\n",
    "    port=39017,\n",
    "    user=\"patrick\",\n",
    "    password=\"Password1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data from the source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = getml.database.connect_mariadb(\n",
    "    host=\"relational.fit.cvut.cz\",\n",
    "    dbname=\"CORA\",\n",
    "    port=3306,\n",
    "    user=\"guest\",\n",
    "    password=\"relational\"\n",
    ")\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if_needed(name):\n",
    "    \"\"\"\n",
    "    Loads the data from the relational learning\n",
    "    repository, if the data frame has not already\n",
    "    been loaded.\n",
    "    \"\"\"\n",
    "    if not getml.data.exists(name):\n",
    "        data_frame = getml.data.DataFrame.from_db(\n",
    "            name=name,\n",
    "            table_name=name,\n",
    "            conn=conn\n",
    "        )\n",
    "        data_frame.save()\n",
    "    else:\n",
    "        data_frame = getml.data.load_data_frame(name)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = load_if_needed(\"paper\")\n",
    "cites = load_if_needed(\"cites\")\n",
    "content = load_if_needed(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare data for getML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getML requires that we define *roles* for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "paper.set_role(\"class_label\", getml.data.roles.categorical)\n",
    "paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cites.set_role([\"cited_paper_id\", \"citing_paper_id\"], getml.data.roles.join_key)\n",
    "cites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to separate our data set into a training, testing and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content.set_role(\"paper_id\", getml.data.roles.join_key)\n",
    "content.set_role(\"word_cited_id\", getml.data.roles.categorical)\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict seven different labels. We generate a target column for each of those labels. We also have to separate the data set into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = getml.data.make_target_columns(paper, \"class_label\")\n",
    "data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = getml.data.split.random(train=0.7, test=0.3, validation=0.0)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = getml.data.Container(population=data_full, split=split)\n",
    "container.add(cites=cites, content=content, paper=paper)\n",
    "container.freeze()\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive modeling\n",
    "\n",
    "We loaded the data and defined the roles and units. Next, we create a getML pipeline for relational learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define relational model\n",
    "\n",
    "To get started with relational learning, we need to specify the data model. Even though the data set itself is quite simple with only three tables and six columns in total, the resulting data model is actually quite complicated.\n",
    "\n",
    "That is because the class label can be predicting using three different pieces of information:\n",
    "\n",
    "- The keywords used by the paper\n",
    "- The keywords used by papers it cites and by papers that cite the paper\n",
    "- The class label of papers it cites and by papers that cite the paper\n",
    "\n",
    "The main challenge here is that `cites` is used twice, once to connect the _cited_ papers and then to connect the _citing_ papers. To resolve this, we need two placeholders on `cites`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = getml.data.DataModel(paper.to_placeholder(\"population\"))\n",
    "\n",
    "# We need two different placeholders for cites.\n",
    "dm.add(getml.data.to_placeholder(cites=[cites]*2, content=content, paper=paper))\n",
    "\n",
    "dm.population.join(\n",
    "    dm.cites[0],\n",
    "    on=('paper_id', 'cited_paper_id')\n",
    ")\n",
    "\n",
    "dm.cites[0].join(\n",
    "    dm.content,\n",
    "    on=('citing_paper_id', 'paper_id')\n",
    ")\n",
    "\n",
    "dm.cites[0].join(\n",
    "    dm.paper,\n",
    "    on=('citing_paper_id', 'paper_id'),\n",
    "    relationship=getml.data.relationship.many_to_one\n",
    ")\n",
    "\n",
    "dm.population.join(\n",
    "    dm.cites[1],\n",
    "    on=('paper_id', 'citing_paper_id')\n",
    ")\n",
    "\n",
    "dm.cites[1].join(\n",
    "    dm.content,\n",
    "    on=('cited_paper_id', 'paper_id')\n",
    ")\n",
    "\n",
    "dm.cites[1].join(\n",
    "    dm.paper,\n",
    "    on=('cited_paper_id', 'paper_id'),\n",
    "    relationship=getml.data.relationship.many_to_one\n",
    ")\n",
    "\n",
    "dm.population.join(\n",
    "    dm.content,\n",
    "    on='paper_id'\n",
    ")\n",
    "\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 getML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### 2.1.1  -->\n",
    "__Set-up the feature learner & predictor__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the relboost algorithms for this problem. Because of the large number of keywords, we regularize the model a bit by requiring a minimum support for the keywords (`min_num_samples`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = getml.preprocessors.Mapping()\n",
    "\n",
    "fast_prop = getml.feature_learning.FastProp(\n",
    "    loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "relboost = getml.feature_learning.Relboost(\n",
    "    num_features=10,\n",
    "    num_subfeatures=10,\n",
    "    loss_function=getml.feature_learning.loss_functions.CrossEntropyLoss,\n",
    "    seed=4367,\n",
    "    num_threads=1,\n",
    "    min_num_samples=30\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Build the pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = getml.pipeline.Pipeline(\n",
    "    tags=['fast_prop'],\n",
    "    data_model=dm,\n",
    "    preprocessors=[mapping],\n",
    "    feature_learners=[fast_prop],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = getml.pipeline.Pipeline(\n",
    "    tags=['relboost'],\n",
    "    data_model=dm,\n",
    "    feature_learners=[relboost],\n",
    "    predictors=[predictor]\n",
    ")\n",
    "\n",
    "pipe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.check(container.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.fit(container.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.check(container.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process seems a bit intimidating. That is because the relboost algorithms needs to train separate models for each class label. This is due to the nature of the generated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.fit(container.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "pipe1.score(container.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.score(container.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things a bit easier, we just look at our test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.scores.filter(lambda score: score.set_used == \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.scores.filter(lambda score: score.set_used == \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Productionization\n",
    "\n",
    "It is possible to productionize the pipeline by transpiling the features into production-ready SQL code. Please also refer to getML's `sqlite3` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.features.to_sql(dialect=getml.pipeline.dialect.spark_sql).save(\"cora1_spark_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.features.to_sql(dialect=getml.pipeline.dialect.spark_sql).save(\"cora2_spark_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_spark = container.train.population.to_pyspark(spark, name=\"population\")\n",
    "cites_spark = cites.to_pyspark(spark, name=\"cites\") \n",
    "content_spark = content.to_pyspark(spark, name=\"content\") \n",
    "paper_spark = paper.to_pyspark(spark, name=\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "getml.spark.execute(spark, \"cora1_spark_sql\")\n",
    "end = time.time()\n",
    "\n",
    "spark_runtime1 = datetime.timedelta(seconds=end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "getml.spark.execute(spark, \"cora2_spark_sql\")\n",
    "end = time.time()\n",
    "\n",
    "spark_runtime2 = datetime.timedelta(seconds=end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "features1 = pipe1.transform(container.train)\n",
    "end = time.time()\n",
    "\n",
    "getml_runtime1 = datetime.timedelta(seconds=end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = time.time()\n",
    "features1 = pipe2.transform(container.train)\n",
    "end = time.time()\n",
    "\n",
    "getml_runtime2 = datetime.timedelta(seconds=end - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_runtime1 / getml_runtime1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_runtime2 / getml_runtime2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "In this notebook we have demonstrated that getML outperforms state-of-the-art relational learning algorithms on the CORA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Dinh, Quang-Thang, Christel Vrain, and Matthieu Exbrayat. \"A Link-Based Method for Propositionalization.\" ILP (Late Breaking Papers). 2012.\n",
    "\n",
    "Motl, Jan, and Oliver Schulte. \"The CTU prague relational learning repository.\" arXiv preprint arXiv:1511.03086 (2015).\n",
    "\n",
    "Perlich, Claudia, and Foster Provost. \"Distribution-based aggregation for relational learning with identifier attributes.\" Machine Learning 62.1-2 (2006): 65-105.\n",
    "\n",
    "Preisach, Christine, and Lars Schmidt-Thieme. \"Relational ensemble classification.\" Sixth International Conference on Data Mining (ICDM'06). IEEE, 2006."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "This tutorial benchmarked getML against academic state-of-the-art algorithms from relational learning literature and getML's qualities with respect to categorical data.\n",
    "\n",
    "If you are interested in further real-world applications of getML, head back to the [notebook overview](welcome.md) and choose one of the remaining examples.\n",
    "\n",
    "Here is some additional material from our [documentation](https://docs.getml.com/latest/) if you want to learn more about getML:\n",
    "* [Feature learning with Multirel](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#multirel)\n",
    "* [Feature learning with Relboost](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#relboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get in contact\n",
    "\n",
    "If you have any question schedule a [call with Alex](https://go.getml.com/meetings/alexander-uhlig/getml-demo), the co-founder of getML, or write us an [email](team@getml.com). Prefer a private demo of getML? Just contact us to make an appointment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
