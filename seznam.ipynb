{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seznam - Predicting the transaction volume\n",
    "\n",
    "*NOTE: Due to the size of the dataset, this notebook will not run on MyBinder.*\n",
    "\n",
    "Seznam is a Czech company with a scope similar to Google. The purpose of this notebook is to analyze data from Seznam's wallet, predicting the transaction volume.\n",
    "\n",
    "Summary:\n",
    "\n",
    "- Prediction type: __Regression model__\n",
    "- Domain: __E-commerce__\n",
    "- Prediction target: __Transaction volume__ \n",
    "- Population size: __1,458,233__\n",
    "\n",
    "_Author: Dr. Patrick Urbanke_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Seznam is a Czech company with a scope similar to Google. The purpose of this notebook is to analyze data from Seznam's wallet, predicting the transaction volume.\n",
    "\n",
    "Since the dataset is in Czech, we will quickly translate the meaning of the main tables:\n",
    "\n",
    "- *dobito*: contains data on prepayments into a wallet\n",
    "- *probehnuto*: contains data on charges from a wallet\n",
    "- *probehnuto_mimo_penezenku*: contains data on charges, from sources other than a wallet\n",
    "\n",
    "The dataset has been downloaded from the [CTU Prague relational learning repository](https://relational.fit.cvut.cz/dataset/Seznam) (Motl and Schulte, 2015).\n",
    "\n",
    "We will benchmark [getML](https://www.getml.com) 's feature learning algorithms against [featuretools](https://www.featuretools.com), an open-source implementation of the propositionalization algorithm, similar to getML's FastProp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A web frontend for getML\n",
    "\n",
    "The getML monitor is a frontend built to support your work with getML. The getML monitor displays information such as the imported data frames, trained pipelines and allows easy data and feature exploration. You can launch the getML monitor [here](http://localhost:1709)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is this running?\n",
    "\n",
    "Your getML live session is running inside a docker container on [mybinder.org](https://mybinder.org/), a service built by the Jupyter community and funded by Google Cloud, OVH, GESIS Notebooks and the Turing Institute. As it is a free service, this session will shut down after 10 minutes of inactivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started with the analysis and set up your session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Connected to project 'seznam'\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "from urllib import request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline  \n",
    "\n",
    "import featuretools\n",
    "import getml\n",
    "\n",
    "getml.set_project('seznam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download from source\n",
    "\n",
    "We begin by downloading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "MySQL error (2005) [HY000] Unknown MySQL server host 'relational.cvut.cz' (-2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-07f780798c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m conn = getml.database.connect_mariadb(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relational.cvut.cz\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdbname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Seznam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3306\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"guest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/getml/database/connect_mariadb.py\u001b[0m in \u001b[0;36mconnect_mariadb\u001b[0;34m(dbname, user, password, host, port, unix_socket, time_formats, conn_id)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Success!\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_exception_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# -------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/getml/communication.py\u001b[0m in \u001b[0;36mengine_exception_handler\u001b[0;34m(msg, fallback)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mfallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: MySQL error (2005) [HY000] Unknown MySQL server host 'relational.cvut.cz' (-2)"
     ]
    }
   ],
   "source": [
    "conn = getml.database.connect_mariadb(\n",
    "    host=\"relational.fit.cvut.cz\",\n",
    "    dbname=\"Seznam\",\n",
    "    port=3306,\n",
    "    user=\"guest\",\n",
    "    password=\"relational\"\n",
    ")\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_if_needed(name):\n",
    "    \"\"\"\n",
    "    Loads the data from the relational learning\n",
    "    repository, if the data frame has not already\n",
    "    been loaded.\n",
    "    \"\"\"\n",
    "    if not getml.data.exists(name):\n",
    "        data_frame = getml.DataFrame.from_db(\n",
    "            name=name,\n",
    "            table_name=name,\n",
    "            conn=conn\n",
    "        )\n",
    "        data_frame.save()\n",
    "    else:\n",
    "        data_frame = getml.data.load_data_frame(name)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobito = load_if_needed(\"dobito\")\n",
    "probehnuto = load_if_needed(\"probehnuto\")\n",
    "probehnuto_mimo_penezenku = load_if_needed(\"probehnuto_mimo_penezenku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probehnuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probehnuto_mimo_penezenku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare data for getML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getML requires that we define *roles* for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobito.set_role(\"client_id\", getml.data.roles.join_key)\n",
    "dobito.set_role(\"month_year_datum_transakce\", getml.data.roles.time_stamp)\n",
    "dobito.set_role(\"sluzba\", getml.data.roles.categorical)\n",
    "dobito.set_role(\"kc_dobito\", getml.data.roles.numerical)\n",
    "\n",
    "dobito.set_unit(\"sluzba\", \"service\")\n",
    "\n",
    "dobito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probehnuto.set_role(\"client_id\", getml.data.roles.join_key)\n",
    "probehnuto.set_role(\"month_year_datum_transakce\", getml.data.roles.time_stamp)\n",
    "probehnuto.set_role(\"sluzba\", getml.data.roles.categorical)\n",
    "probehnuto.set_role(\"kc_proklikano\", getml.data.roles.target)\n",
    "\n",
    "probehnuto.set_unit(\"sluzba\", \"service\")\n",
    "\n",
    "probehnuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probehnuto_mimo_penezenku.set_role(\"client_id\", getml.data.roles.join_key)\n",
    "probehnuto_mimo_penezenku.set_role(\"Month/Year\", getml.data.roles.time_stamp)\n",
    "\n",
    "probehnuto_mimo_penezenku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = getml.data.split.random(train=0.8, test=0.2)\n",
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive modeling\n",
    "\n",
    "We loaded the data and defined the roles and units. Next, we create a getML pipeline for relational learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define relational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_schema = getml.data.StarSchema(population=probehnuto, alias=\"population\", split=split)\n",
    "\n",
    "star_schema.join(\n",
    "    probehnuto,\n",
    "    on=\"client_id\",\n",
    "    time_stamps=\"month_year_datum_transakce\",\n",
    "    lagged_targets=True,\n",
    "    horizon=getml.data.time.days(1),\n",
    ")\n",
    "\n",
    "star_schema.join(\n",
    "    dobito,\n",
    "    on=\"client_id\",\n",
    "    time_stamps=\"month_year_datum_transakce\",\n",
    ")\n",
    "\n",
    "star_schema.join(\n",
    "    probehnuto_mimo_penezenku,\n",
    "    on=\"client_id\", \n",
    "    time_stamps=(\"month_year_datum_transakce\",  \"Month/Year\"),\n",
    ")\n",
    "\n",
    "star_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 getML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### 2.1.1  -->\n",
    "__Set-up the feature learner & predictor__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the relboost algorithms for this problem. Because of the large number of keywords, we regularize the model a bit by requiring a minimum support for the keywords (`min_num_samples`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = getml.preprocessors.Mapping()\n",
    "\n",
    "fast_prop = getml.feature_learning.FastProp(\n",
    "    aggregation=getml.feature_learning.FastProp.agg_sets.All,\n",
    "    loss_function=getml.feature_learning.loss_functions.SquareLoss,\n",
    "    num_threads=1,    \n",
    "    sampling_factor=0.1,\n",
    ")\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor(n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Build the pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = getml.Pipeline(\n",
    "    tags=['fast_prop'],\n",
    "    data_model=star_schema.data_model,\n",
    "    preprocessors=[mapping],\n",
    "    feature_learners=[fast_prop],\n",
    "    predictors=[predictor],\n",
    "    include_categorical=True,\n",
    ")\n",
    "\n",
    "pipe1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.check(star_schema.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.fit(star_schema.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.score(star_schema.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include = (getml.data.random() < 0.25)\n",
    "include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_train_pd = star_schema.train.population[include].to_pandas()\n",
    "population_test_pd = star_schema.test.population.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_train_pd[\"id\"] = population_train_pd.index\n",
    "population_test_pd[\"id\"] = population_test_pd.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probehnuto_pd = probehnuto.drop(probehnuto.roles.unused).to_pandas()\n",
    "dobito_pd = dobito.drop(dobito.roles.unused).to_pandas()\n",
    "probehnuto_mimo_penezenku_pd = probehnuto_mimo_penezenku.drop(probehnuto_mimo_penezenku.roles.unused).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_peripheral(peripheral_pd, train_or_test):\n",
    "    \"\"\"\n",
    "    Helper function that imitates the behavior of \n",
    "    the data model defined above.\n",
    "    \"\"\"\n",
    "    peripheral_new = peripheral_pd.merge(\n",
    "        train_or_test[[\"id\", \"client_id\", \"month_year_datum_transakce\"]],\n",
    "        on=\"client_id\"\n",
    "    )\n",
    "\n",
    "    peripheral_new = peripheral_new[\n",
    "        peripheral_new[\"month_year_datum_transakce_x\"] < peripheral_new[\"month_year_datum_transakce_y\"]\n",
    "    ]\n",
    "\n",
    "    del peripheral_new[\"month_year_datum_transakce_y\"]\n",
    "    del peripheral_new[\"client_id\"]\n",
    "\n",
    "    return peripheral_new.rename({\"month_year_datum_transakce_y\": \"month_year_datum_transakce\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_probehnuto_mimo_penezenku(peripheral_pd, train_or_test):\n",
    "    \"\"\"\n",
    "    Helper function that imitates the behavior of \n",
    "    the data model defined above.\n",
    "    \"\"\"\n",
    "    peripheral_new = peripheral_pd.merge(\n",
    "        train_or_test[[\"id\", \"client_id\", \"month_year_datum_transakce\"]],\n",
    "        on=\"client_id\"\n",
    "    )\n",
    "\n",
    "    peripheral_new = peripheral_new[\n",
    "        peripheral_new[\"Month/Year\"] < peripheral_new[\"month_year_datum_transakce\"]\n",
    "    ]\n",
    "\n",
    "    del peripheral_new[\"month_year_datum_transakce\"]\n",
    "    del peripheral_new[\"client_id\"]\n",
    "\n",
    "    return peripheral_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobito_train_pd = prepare_peripheral(dobito_pd, population_train_pd)\n",
    "dobito_test_pd = prepare_peripheral(dobito_pd, population_test_pd)\n",
    "dobito_train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probehnuto_train_pd = prepare_peripheral(probehnuto_pd, population_train_pd)\n",
    "probehnuto_test_pd = prepare_peripheral(probehnuto_pd, population_test_pd)\n",
    "probehnuto_train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probehnuto_mimo_penezenku_train_pd = prepare_probehnuto_mimo_penezenku(probehnuto_mimo_penezenku_pd, population_train_pd)\n",
    "probehnuto_mimo_penezenku_test_pd = prepare_probehnuto_mimo_penezenku(probehnuto_mimo_penezenku_pd, population_test_pd)\n",
    "probehnuto_mimo_penezenku_train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del population_train_pd[\"client_id\"]\n",
    "del population_test_pd[\"client_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_train = {\n",
    "    \"population\" : (population_train_pd, \"id\"),\n",
    "    \"dobito\": (dobito_train_pd, \"index\"),\n",
    "    \"probehnuto\": (probehnuto_train_pd, \"index\"),\n",
    "    \"probehnuto_mimo_penezenku\": (probehnuto_mimo_penezenku_train_pd, \"index\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_test = {\n",
    "    \"population\" : (population_test_pd, \"id\"),\n",
    "    \"dobito\": (dobito_test_pd, \"index\"),\n",
    "    \"probehnuto\": (probehnuto_test_pd, \"index\"),\n",
    "    \"probehnuto_mimo_penezenku\": (probehnuto_mimo_penezenku_test_pd, \"index\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = [\n",
    "    (\"population\", \"id\", \"dobito\", \"id\"),\n",
    "    (\"population\", \"id\", \"probehnuto\", \"id\"),\n",
    "    (\"population\", \"id\", \"probehnuto_mimo_penezenku\", \"id\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuretools_train_pd = featuretools.dfs(\n",
    "    dataframes=dataframes_train,\n",
    "    relationships=relationships,\n",
    "    target_dataframe_name=\"population\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuretools_test_pd = featuretools.dfs(\n",
    "    dataframes=dataframes_test,\n",
    "    relationships=relationships,\n",
    "    target_dataframe_name=\"population\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuretools_train = getml.data.DataFrame.from_pandas(featuretools_train_pd, \"featuretools_train\")\n",
    "featuretools_test = getml.data.DataFrame.from_pandas(featuretools_test_pd, \"featuretools_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuretools_train.set_role(\"kc_proklikano\", getml.data.roles.target)\n",
    "featuretools_train.set_role(featuretools_train.roles.unused_float, getml.data.roles.numerical)\n",
    "featuretools_train.set_role(featuretools_train.roles.unused_string, getml.data.roles.categorical)\n",
    "\n",
    "featuretools_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuretools_test.set_role(\"kc_proklikano\", getml.data.roles.target)\n",
    "featuretools_test.set_role(featuretools_test.roles.unused_float, getml.data.roles.numerical)\n",
    "featuretools_test.set_role(featuretools_test.roles.unused_string, getml.data.roles.categorical)\n",
    "\n",
    "featuretools_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train an untuned XGBoostRegressor on top of featuretools' features, just like we have done for getML's features.\n",
    "\n",
    "Since some of featuretools features are categorical, we allow the pipeline to include these features as well. Other features contain NaN values, which is why we also apply getML's Imputation preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = getml.data.DataModel(\"population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputation = getml.preprocessors.Imputation()\n",
    "\n",
    "predictor = getml.predictors.XGBoostRegressor(n_jobs=1)\n",
    "\n",
    "pipe2 = getml.Pipeline(\n",
    "    tags=['featuretools'],\n",
    "    data_model=data_model,\n",
    "    preprocessors=[imputation],\n",
    "    predictors=[predictor],\n",
    "    include_categorical=True,\n",
    ")\n",
    "\n",
    "pipe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.fit(featuretools_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.score(featuretools_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Features\n",
    "\n",
    "The most important feature looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.features.to_sql()[pipe1.features.sort(by=\"importances\")[0].name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Productionization\n",
    "\n",
    "It is possible to productionize the pipeline by transpiling the features into production-ready SQL code. Please also refer to getML's `sqlite3` and `spark` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a folder named seznam_pipeline containing\n",
    "# the SQL code.\n",
    "pipe1.features.to_sql().save(\"seznam_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.features.to_sql(dialect=getml.pipeline.dialect.spark_sql).save(\"seznam_spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Discussion\n",
    "\n",
    "For a more convenient overview, we summarize our results into a table.\n",
    "\n",
    "Name                 | R-squared  | RMSE   | MAE\n",
    "-------------------- | ---------- | -------| ----\n",
    "getML: FastProp      |     78.22% | 24,480 | 3,160\n",
    "featuretools         |     63.24% | 31,655 | 5,167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "We have benchmarked getML against featuretools on a dataset related to online transactions. We have found that getML outperforms featuretools by a wide margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Motl, Jan, and Oliver Schulte. \"The CTU prague relational learning repository.\" arXiv preprint arXiv:1511.03086 (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "This tutorial benchmarked getML against academic state-of-the-art algorithms from relational learning literature and getML's qualities with respect to categorical data.\n",
    "\n",
    "If you are interested in further real-world applications of getML, head back to the [notebook overview](welcome.md) and choose one of the remaining examples.\n",
    "\n",
    "Here is some additional material from our [documentation](https://docs.getml.com/latest/) if you want to learn more about getML:\n",
    "* [Feature learning with Multirel](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#multirel)\n",
    "* [Feature learning with Relboost](https://docs.getml.com/latest/user_guide/feature_engineering/feature_engineering.html#relboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get in contact\n",
    "\n",
    "If you have any question schedule a [call with Alex](https://go.getml.com/meetings/alexander-uhlig/getml-demo), the co-founder of getML, or write us an [email](team@getml.com). Prefer a private demo of getML? Just contact us to make an appointment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
